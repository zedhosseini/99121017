# -*- coding: utf-8 -*-
"""version3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bkjmM0FE3H8bSUQZ5QV1LfXxpHq89LF6
"""

!pip install streamlit pyngrok opencv-python==4.7.0.72 retina-face tensorflow==2.12 keras==2.12

# RetinaFace
!wget https://github.com/deepinsight/insightface/releases/download/v0.1/retinaface-R50.zip
!unzip -o retinaface-R50.zip

# مدل DEX برای تشخیص سن
!wget -O dex_imdb_wiki.caffemodel https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/dex_imdb_wiki.caffemodel
!wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/age.prototxt

# مدل Mini-XCEPTION برای تشخیص احساسات
!wget https://github.com/oarriaga/face_classification/raw/master/trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# from retinaface import RetinaFace
# from tensorflow.keras.models import load_model
# 
# # Load models
# age_net = cv2.dnn.readNetFromCaffe("age.prototxt", "dex_imdb_wiki.caffemodel")
# emotion_model = load_model("fer2013_mini_XCEPTION.102-0.66.hdf5")
# emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
# 
# def detect_faces(img):
#     rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#     faces = RetinaFace.detect_faces(rgb_img)
#     face_boxes = []
#     if isinstance(faces, dict):
#         for face in faces.values():
#             x, y, x2, y2 = face["facial_area"]
#             face_boxes.append((x, y, x2 - x, y2 - y))
#     return face_boxes
# 
# def predict_age(face_img):
#     blob = cv2.dnn.blobFromImage(face_img, 1.0, (224, 224),
#                                  (78.4263377603, 87.7689143744, 114.5902774601))
#     age_net.setInput(blob)
#     age_pred = age_net.forward()
#     return int(age_pred[0].dot(np.arange(0, 101)).flatten())
# 
# def predict_emotion(face_img):
#     face_gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
#     face_resized = cv2.resize(face_gray, (64, 64))
#     face_processed = face_resized.reshape(1, 64, 64, 1).astype('float32') / 255.0
#     emotion_pred = emotion_model.predict(face_processed)
#     return emotion_labels[np.argmax(emotion_pred)]
# 
# # UI
# st.title("Face , Age and Emotion Detection")
# 
# uploaded_file = st.file_uploader("Upload an image", type=["jpg", "png", "jpeg"])
# if uploaded_file is not None:
#     file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
#     img = cv2.imdecode(file_bytes, 1)
# 
#     st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption="Original Image", use_container_width=True)
# 
#     faces = detect_faces(img)
# 
#     for (x, y, w, h) in faces:
#         face_img = img[y:y+h, x:x+w]
#         age = predict_age(face_img)
#         emotion = predict_emotion(face_img)
# 
#         cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
#         cv2.putText(img, f"Age: {age}", (x, y - 10),
#                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
#         cv2.putText(img, f"Emotion: {emotion}", (x, y + h + 20),
#                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
# 
#     st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), caption="Processed Image", use_container_width=True)
#

from pyngrok import ngrok

# بستن تونل‌های قبلی
ngrok.kill()

# وارد کردن توکن ngrok
ngrok.set_auth_token("2wxR3KkHTgTibLY7qMnZSvNkjd1_7R8YB4cdZKQLdYthiJ7tr")

# ایجاد تونل به پورت استریملت
public_url = ngrok.connect(8501)
print("URL:", public_url)

# اجرای استریملت
!streamlit run app.py &>/dev/null &